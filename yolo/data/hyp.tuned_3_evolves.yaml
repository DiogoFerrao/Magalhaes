lr0: 0.00793  # initial learning rate (SGD=1E-2, Adam=1E-3) (bigger learning rate combined with a larger bash size is a good idea)
lrf: 0.21  # final OneCycleLR learning rate (lr0 * lrf)
momentum: 0.918  # SGD momentum/Adam beta1 (between 0.9 and 0.99)
weight_decay: 0.00041  # optimizer weight decay 5e-4 (smaller datasets require a larger weight decay value and the opposite is also true)
warmup_epochs: 2.96  # warmup epochs (fractions ok) (# epochs where the learning rate grows from 0 in the initial epoch to lr0 in the last epoch)
warmup_momentum: 0.88  # warmup initial momentum
warmup_bias_lr: 0.105  # warmup initial bias lr


box: 0.05  # box loss gain
cls: 0.404  # cls loss gain
cls_pw: 1.03  # cls BCELoss positive_weight
obj: 0.725  # obj loss gain (scale with pixels)
obj_pw: 1.2  # obj BCELoss positive_weight
iou_t: 0.20  # IoU training threshold
anchor_t: 3.86  # anchor-multiple threshold
# anchors: 3  # anchors per output layer (0 to ignore)
fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)
hsv_h: 0.0122  # image HSV-Hue augmentation (fraction)
hsv_s: 0.646  # image HSV-Saturation augmentation (fraction)
hsv_v: 0.354  # image HSV-Value augmentation (fraction)
degrees: 0.0  # image rotation (+/- deg)
translate: 0.104  # image translation (+/- fraction)
scale: 0.9  # image scale (+/- gain)
shear: 0.0  # image shear (+/- deg)
perspective: 0.0  # image perspective (+/- fraction), range 0-0.001
flipud: 0.0  # image flip up-down (probability)
fliplr: 0.5  # image flip left-right (probability)
mosaic: 0.868  # image mosaic (probability)
mixup: 0.0  # image mixup (probability)
